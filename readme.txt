Нейронная сеть.
Реализована полносвязная нейронная сеть (fully connected neural network).
Симуляция созданная по мотивам https://my-js.org/docs/guide/shorelark
Та НС, которая была в оригинале так и осталась, но только для проверки и теста, т.е.
сверки результатов новой и старой НС.
НС в модуле flex_net. При этом soft_net - первая попытка сделать
такую НС и сейчас не используется, но пока не удалена.
НС существует в 2-х ипостасях:
- В виде топологии LayerTopologyFlex. В таком виде её будет удобно хранить на диске и из него
разворачивать сеть по умолчанию. Также топология совпадает с Chromosome.genes, что удобно
для обучения через ГА. Она хранится в Vec<(f32, usize, usize, usize)>.
Состав структуры (bias or weight, layer_num, neuron_out, neuron_in).
Для примера:
//входной слой - 3 входа, 3 выхода. У вх. слоя bias = 0.0, а вес = 1.0.
(0.0,1,1,0) - смещение 1 слоя 1 нейрона (связь на 0), (1.0,1,1,1), - вх.связь 1 вх.-> 1 нейрон
(0.0,1,2,0),(1.0,1,2,2),//2
(0.0,1,3,0),(1.0,1,3,3),//3
//первый слой - 2 нейрона. 3 входа, 2 выхода
(0.1,2,4,0) - смещение ,(-0.5,2,4,1),(-0.4,2,4,2),(-0.3,2,4,3) - вх.связи 1->4,2->4,3->4//4
(0.2,2,5,0),(-0.2,2,5,1),(-0.1,2,5,2),(0.0,2,5,3),//5
//второй слой - 1 нейрон. 2 входа, 1 выход
(0.3,3,6,0),(-0.5,3,6,4),(0.5,3,6,5)//6

- В виде развернутой сети FlexNetwork. В таком виде удобно делать propagate и представлять
веса в виде тензора.
Создание сети может быть из весов (в них указана топология сети) через метод (from_weights). При
этом создаются вх.связи для каждого нейрона: inp_links, также список номеров нейронов по слоям -
neurons и список функций активации каждого слоя activations. Эти 3 атрибута используются для
создания сети через (new).
Если inp_links надо заполнить из топологии нужно использовать (input_links).
А еще создать сеть можно со случайными весами и указанной топологией через метод (random). При
этом для создания inp_links исп. (input_links_rand), для neurons - (neurons), для activations -
(activations).
Когда нужно наоборот сеть перевести в топологию нужно использовать (weights).
При создании сети (new) создаются тензоры из neurons и inp_links через (tensors). Они нужны
для расчетов.
У FlexNetwork прямой проход (propagate), для расчета используется фреймворк Candle.
Все смещения по всем слоям находятся в тензоре layers_biases: Vec<Tensor>. Все веса по всем
слоям находятся в тензоре layers_weights: Vec<Tensor>. Список функций активации каждого
слоя в HashMap<usize, candle_nn::Activation>. Все это используется для создания модели
методом (model). И сразу после этого используется (forward) модели. Получается, что при каждом
(propagate) из тензоров и активаций создается модель, а потом у неё вызывается (forward).
Может быть потом надо будет сделать создание модели при создании сети (new), также как создаются
тензоры.
Как, наверное, уже заметили у сети нет функций обучения через back propagation. Обучение
происходит в ГА в другом проекте genetic-algorithm.